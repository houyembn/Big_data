input {
  # Input générique pour les fichiers CSV et JSON
  file {
    path => "/usr/share/logstash/logs/*.{csv,json}"  # Accepte les fichiers CSV et JSON
    start_position => "beginning"
    sincedb_path => "/dev/null"
    discover_interval => 10  # Vérifie les nouveaux fichiers toutes les 10 secondes
  }
}

filter {
  if [path] =~ "\.csv$" {
    csv {
      separator => ","
      autodetect_column_names => true  # Détection automatique des noms de colonnes
      skip_header => true  # Ignore la première ligne si c'est une en-tête
    }
  }

  if [path] =~ "\.json$" {
   json {
    source => "message"  # Assurez-vous que "message" est le champ contenant le JSON
  }
  }
}

# output {
#   stdout { codec => rubydebug }  # Affiche les données dans la console pour le débogage
#   elasticsearch {
#     hosts => ["http://elasticsearch:9200"]  # Nom du conteneur Elasticsearch
#     index => "logstash-%{+YYYY.MM.dd}"  # Crée un index quotidien
#     document_type => "_doc"  # Utilisation du type par défaut "_doc"
#   }
output {
  stdout { codec => rubydebug }

  if [path] =~ "\.csv$" {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "logstash-csv-%{+YYYY.MM.dd}"
      document_type => "_doc"
    }
  }

  if [path] =~ "\.json$" {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "logstash-json-%{+YYYY.MM.dd}"
      document_type => "_doc"
    }
  }


}

